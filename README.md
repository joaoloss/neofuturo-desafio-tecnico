# neofuturo-desafio-tecnico

## üìù Descri√ß√£o do problema

O [desafio](./desc.md) consiste na cria√ß√£o de um algoritmo de agrupamento eficiente e escal√°vel para identificar e agrupar itens equivalentes a partir de suas descri√ß√µes textuais. Essas descri√ß√µes podem apresentar varia√ß√µes, como abrevia√ß√µes, diferen√ßas na ordem das informa√ß√µes, uso de sin√¥nimos e pequenas inconsist√™ncias textuais, o que torna o problema n√£o trivial.

## üíª Stack

- **Linguagem:** [Python](https://www.python.org/)
- **Framework:** [FastAPI](https://fastapi.tiangolo.com/)

## üí° Estrat√©gia

### Similaridade entre strings

Para comparar duas descri√ß√µes textuais (strings), foram testadas duas m√©tricas de dissimilaridade: [Jaccard](https://en.wikipedia.org/wiki/Jaccard_index) (complexidade $O(N)$, onde $N$ √© o tamanho da uni√£o) e a [dist√¢ncia de Levenshtein](https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_Levenshtein) (complexidade $O(N \times M)$, onde $N$ e $M$ s√£o os comprimentos das duas strings comparadas). Tamb√©m foi avaliada uma pondera√ß√£o entre essas m√©tricas. Os testes, resultados e visualiza√ß√µes podem ser consultados no [notebook de testes](./tests.ipynb).

Os resultados mostraram-se bastante satisfat√≥rios, especialmente quando se utiliza a combina√ß√£o ponderada das duas m√©tricas.

**Nota**: como forma de normaliza√ß√£o, optou-se pelo uso de uma [ferramenta de stemming](https://www.nltk.org/_modules/nltk/stem/rslp.html) antes do c√°lculo das m√©tricas.

**Nota**: os pesos utilizados na pondera√ß√£o entre as m√©tricas, assim como os *thresholds*, foram definidos empiricamente.

#### Quando a m√©trica n√£o √© suficiente

Existem situa√ß√µes em que as m√©tricas de similaridade textual, por si s√≥, n√£o s√£o suficientes para tomar uma decis√£o confi√°vel de agrupamento. Isso pode ocorrer, por exemplo, quando diferentes itens compartilham termos semelhantes, mas representam conceitos distintos, ou quando descri√ß√µes semanticamente equivalentes apresentam baixa similaridade.

Nesses casos, o sistema recorre a um modelo de linguagem para apoiar a decis√£o. Dado um item e um conjunto de itens candidatos (composto pelos mais similares), o modelo √© utilizado para avaliar se o item deve ser associado a um grupo existente ou se a cria√ß√£o de um novo grupo √© mais apropriada. Essa abordagem permite capturar rela√ß√µes sem√¢nticas mais sutis que n√£o s√£o plenamente refletidas pelas m√©tricas de similaridade baseadas em string.

Dessa forma, o modelo de linguagem atua como uma etapa complementar ao algoritmo de agrupamento, sendo acionado apenas quando as m√©tricas tradicionais n√£o atingem um n√≠vel de confian√ßa suficiente. Essa estrat√©gia equilibra precis√£o e efici√™ncia, reduzindo o n√∫mero de chamadas ao modelo e mantendo o sistema escal√°vel.

O [notebook de testes](./tests.ipynb) mostra que mesmo um modelo pequeno, barato e com *reasoning* minimizado foi extremamente preciso.

### Escolha e persist√™ncia de colunas relevantes

Considerando que a entrada do sistema √© um arquivo estruturado (representando um cat√°logo de itens) contendo uma tabela, surge um segundo desafio: identificar quais colunas s√£o relevantes para descrever os itens. Para abordar esse problema, optou-se pela utiliza√ß√£o de um modelo de linguagem. Como a tarefa √© relativamente simples, foi escolhido um modelo pequeno e r√°pido; al√©m disso, o n√≠vel de *reasoning* foi minimizado, reduzindo lat√™ncia e custo.

Conforme evidenciado no [notebook](./tests.ipynb), o modelo de linguagem apresentou (novamente) um √≥timo desempenho.

Adicionalmente, para evitar chamadas redundantes ao modelo, foi criado um conjunto de *hashes* a partir das colunas, de modo que documentos com as mesmas colunas (mesmo que em ordens diferentes) n√£o gerem m√∫ltiplas chamadas ao modelo.

### Feedback e altera√ß√£o humana

Um endpoint dedicado foi projetado para permitir interven√ß√£o humana no processo de agrupamento, possibilitando a corre√ß√£o manual de decis√µes tomadas automaticamente pelo algoritmo. A principal motiva√ß√£o √© reconhecer que, apesar da efic√°cia das m√©tricas de similaridade e do uso pontual de modelos de linguagem, casos amb√≠guos ou espec√≠ficos do dom√≠nio podem exigir valida√ß√£o humana.

Por meio do endpoint, √© poss√≠vel mover manualmente um item de um grupo para outro, ou ainda for√ßar a cria√ß√£o de um novo grupo. Opcionalmente, o usu√°rio pode fornecer uma lista de *keywords* relevantes, que passam a caracterizar o grupo de destino. Essas palavras-chave s√£o utilizadas como sinais adicionais em an√°lises futuras, ajudando a refor√ßar a identidade sem√¢ntica do grupo.

Ap√≥s a realoca√ß√£o do item, o sistema executa uma etapa de verifica√ß√£o para identificar itens potencialmente mal posicionados. Essa verifica√ß√£o analisa os itens do grupo de origem em rela√ß√£o ao grupo de destino, buscando casos em que outros itens possam ter sido afetados pela corre√ß√£o manual e tamb√©m devam ser reconsiderados. Os itens considerados suspeitos s√£o retornados na resposta do endpoint.

Dessa forma, o endpoint n√£o apenas permite a corre√ß√£o pontual de um erro, mas tamb√©m promove um ciclo de feedback humano no processo de agrupamento, auxiliando na identifica√ß√£o de inconsist√™ncias e contribuindo para a melhoria cont√≠nua da qualidade dos grupos ao longo do tempo.

## üìÇ Estrutura do projeto

- **Arquivos na raiz**
  - `README.md`: documenta√ß√£o principal do projeto, contendo a descri√ß√£o do problema, abordagem adotada e instru√ß√µes de uso.
  - `desc.md`: descri√ß√£o detalhada do desafio proposto.
  - `pyproject.toml`, `.python-version` e `uv.lock`: arquivos de configura√ß√£o do ambiente e depend√™ncias.
  - `tests.ipynb`: notebook contendo experimentos e resultados a partir dos quais decis√µes t√©cnicas foram tomadas.
  - `dump/`: diret√≥rio utilizado para persistir o estado dos agrupamentos para inspe√ß√£o ap√≥s encerrar a API.
  - `exemplos/`: arquivos CSV de exemplo, representando cat√°logos de diferentes fornecedores.

- **src/**
  - `main.py`: ponto de entrada da aplica√ß√£o e defini√ß√£o dos endpoints da API.
  - `state.py`: defini√ß√£o do estado global da aplica√ß√£o, respons√°vel por armazenar grupos, itens, caches e mecanismos de sincroniza√ß√£o.
  - `config/`: configura√ß√µes gerais da aplica√ß√£o, incluindo *settings*, *logging* e *prompts* utilizados pelo modelo de linguagem.
  - `domain/`: defini√ß√£o das entidades centrais do dom√≠nio.
  - `llm/`: abstra√ß√£o e integra√ß√£o com o modelo de linguagem utilizado para decis√µes sem√¢nticas.
  - `service/`: servi√ßos que encapsulam a l√≥gica de aplica√ß√£o, como cria√ß√£o de itens a partir de CSVs, agrupamento autom√°tico e identifica√ß√£o de itens suspeitos.

## üë®üèª‚Äçüíª Como usar

1. Clone o reposit√≥rio
```bash
git clone https://github.com/joaoloss/neofuturo-desafio-tecnico.git
cd neofuturo-desafio-tecnico
```

2. Crie um `.env`
```
OPENAI_API_KEY=<sua-chave-api>
LLM_MODEL_NAME=<gpt-5-nano-2025-08-07 ou outro modelo>
```

3. Inicialize o ambiente com [uv](https://docs.astral.sh/uv/)
```bash
uv sync
```

4. Execu√ß√£o do Programa
```bash
uv run fastapi run ./src/main.py
```

## üß© Melhorias e limita√ß√µes reconhecidas

Como o algoritmo √© apenas um prot√≥tipo, √© importante pontuar limita√ß√µes/melhorias reconhecidas:

1. Tratativa de erros.
2. Suporte para mais tipos de arquivo.
3. Armazenamento em mem√≥ria: para simplificar o desenvolvimento e acelerar testes, optou-se por n√£o utilizar um SGBD. Todo o estado da aplica√ß√£o √© mantido em mem√≥ria e, portanto, √© perdido ap√≥s o encerramento do programa. Uma evolu√ß√£o natural seria a persist√™ncia dos dados em um banco de dados.
4. Atualmente, a cria√ß√£o de *keywords* associadas aos grupos ocorre apenas ap√≥s interven√ß√£o manual humana. √â poss√≠vel evoluir esse mecanismo para uma abordagem mais din√¢mica, em que as *keywords* sejam automaticamente inferidas a partir dos termos mais frequentes ou mais representativos dos itens de cada grupo.
5. Estrat√©gias de encurtamento de descri√ß√µes (removendo palavras irrelevantes ou pouco significativas) podem se mostrar essencias pensando em escalabilidade.
6. Os pesos das m√©tricas de similaridade e os *thresholds* foram definidos empiricamente. Uma poss√≠vel melhoria seria automatizar esse processo por meio de valida√ß√£o com dados rotulados, otimiza√ß√£o de hiperpar√¢metros ou t√©cnicas adaptativas que ajustem esses valores ao longo do tempo.