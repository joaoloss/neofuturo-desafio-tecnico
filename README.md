# neofuturo-desafio-tecnico

## üìù Descri√ß√£o do problema

O [desafio](./desc.md) consiste na cria√ß√£o de um algoritmo de agrupamento eficiente e escal√°vel para identificar e agrupar itens equivalentes a partir de suas descri√ß√µes textuais. Essas descri√ß√µes podem apresentar varia√ß√µes, como abrevia√ß√µes, diferen√ßas na ordem das informa√ß√µes, uso de sin√¥nimos e pequenas inconsist√™ncias textuais, o que torna o problema n√£o trivial.

## üíª Stack

- **Linguagem:** [Python](https://www.python.org/)
- **Framework:** [FastAPI](https://fastapi.tiangolo.com/)

## üí° Estrat√©gia

### Similaridade entre strings

Para comparar duas descri√ß√µes textuais (strings), foram testadas duas m√©tricas de dissimilaridade: [Jaccard](https://en.wikipedia.org/wiki/Jaccard_index) (complexidade $O(N)$, onde $N$ √© o tamanho da uni√£o) e a [dist√¢ncia de Levenshtein](https://pt.wikipedia.org/wiki/Dist%C3%A2ncia_Levenshtein) (complexidade $O(N \times M)$, onde $N$ e $M$ s√£o os comprimentos das duas strings comparadas). Tamb√©m foi avaliada uma pondera√ß√£o entre essas m√©tricas. Os testes, resultados e visualiza√ß√µes podem ser consultados no [notebook de testes](./tests.ipynb).

Os resultados mostraram-se bastante satisfat√≥rios, especialmente quando se utiliza a combina√ß√£o ponderada das duas m√©tricas.

**Nota**: como forma de normaliza√ß√£o, optou-se pelo uso de uma [ferramenta de stemming](https://www.nltk.org/_modules/nltk/stem/rslp.html) antes do c√°lculo das m√©tricas.

**Nota**: os pesos utilizados na pondera√ß√£o entre as m√©tricas, assim como os *thresholds*, foram definidos empiricamente.

#### Quando a m√©trica n√£o √© suficiente

##### Modelo de linguagem

Existem situa√ß√µes em que as m√©tricas de similaridade textual, por si s√≥, n√£o s√£o suficientes para tomar uma decis√£o confi√°vel de agrupamento. Isso pode ocorrer, por exemplo, quando diferentes itens compartilham termos semelhantes, mas representam conceitos distintos, ou quando descri√ß√µes semanticamente equivalentes apresentam baixa similaridade.

Nesses casos, o sistema recorre a um modelo de linguagem para apoiar a decis√£o. Dado um item e um conjunto de itens candidatos (composto pelos mais similares), o modelo √© utilizado para avaliar se o item deve ser associado a um grupo existente ou se a cria√ß√£o de um novo grupo √© mais apropriada. Essa abordagem permite capturar rela√ß√µes sem√¢nticas mais sutis que n√£o s√£o plenamente refletidas pelas m√©tricas de similaridade baseadas em string.

Dessa forma, o modelo de linguagem atua como uma etapa complementar ao algoritmo de agrupamento, sendo acionado apenas quando as m√©tricas tradicionais n√£o atingem um n√≠vel de confian√ßa suficiente. Essa estrat√©gia equilibra precis√£o e efici√™ncia, reduzindo o n√∫mero de chamadas ao modelo e mantendo o sistema escal√°vel.

O [notebook de testes](./tests.ipynb) mostra que mesmo um modelo pequeno, barato e com *reasoning* minimizado foi extremamente preciso.

√â interessante notar que as chamadas ao modelo de linguagem representam o principal gargalo de desempenho do sistema. Esse impacto pode ser claramente observado no seguinte exemplo de execu√ß√£o:

```
[INFO - 2026-01-08 21:53:13,398] Grouped 52 items in 39.70 seconds. LLM latency: 39.69 seconds. LLM usage: 15/52.
```

Nesse caso, embora o modelo de linguagem tenha sido acionado para apenas **15 dos 52 itens processados**, praticamente **todo o tempo total de execu√ß√£o** (39,69s de 39,70s) foi consumido pelas chamadas ao LLM. Isso evidencia que a lat√™ncia associada ao modelo domina o custo computacional do pipeline, enquanto as etapas baseadas em m√©tricas de similaridade textual possuem impacto praticamente desprez√≠vel no tempo total.

Esse exemplo refor√ßa a necessidade de acionar o modelo de linguagem apenas quando estritamente necess√°rio, bem como a import√¢ncia de heur√≠sticas eficientes para reduzir o n√∫mero de chamadas sem comprometer a qualidade dos agrupamentos.

##### Conjunto de palavras chave

Outro ponto fraco das m√©tricas aparece nos casos em que itens distintos compartilham descri√ß√µes quase id√™nticas, diferindo apenas por termos altamente espec√≠ficos (por exemplo, o nome de uma linha ou modelo).

Para mitigar esse problema, cada grupo possui um conjunto de palavras-chave que o caracterizam de forma mais precisa. Essas palavras-chave funcionam como um sinal adicional de verifica√ß√£o: ao comparar um novo item com um grupo candidato, avalia-se se a descri√ß√£o do item cont√©m uma fra√ß√£o significativa (n√∫mero ajustado) dessas palavras. Caso contr√°rio, mesmo que a similaridade textual seja alta, o item n√£o √© automaticamente atribu√≠do ao grupo (nesses casos, o modelo de linguagem √© acionado).

O [notebook de testes](./tests.ipynb) mostra tanto a dificuldade das m√©tricas com esses casos quanto a performance do modelo de linguagem em identificar as palavras-chave dado um conjunto de itens equivalentes.

**Nota**: como ser√° visto adiante, atualmente a cria√ß√£o de palavras-chave associadas aos grupos ocorre apenas ap√≥s interven√ß√£o manual humana. Por√©m, √© evidente que esse processo pode ser aprimorado e automatizado, seja por meio do uso do modelo de linguagem, seja pela aplica√ß√£o de t√©cnicas estat√≠sticas como [TF-IDF](https://pt.wikipedia.org/wiki/Tf%E2%80%93idf), uma abordagem que n√£o foi explorada neste prot√≥tipo, mas que se mostra promissora dado o contexto do problema.

### Escolha e persist√™ncia de colunas relevantes

Considerando que a entrada do sistema √© um arquivo estruturado (representando um cat√°logo de itens) contendo uma tabela, surge um segundo desafio: identificar quais colunas s√£o relevantes para descrever os itens. Para abordar esse problema, optou-se pela utiliza√ß√£o de um modelo de linguagem. Como a tarefa √© relativamente simples, foi escolhido um modelo pequeno e r√°pido; al√©m disso, o n√≠vel de *reasoning* foi minimizado, reduzindo lat√™ncia e custo.

Conforme evidenciado no [notebook](./tests.ipynb), o modelo de linguagem apresentou (novamente) um √≥timo desempenho.

Adicionalmente, para evitar chamadas redundantes ao modelo, foi criado um conjunto de *hashes* a partir das colunas, de modo que documentos com as mesmas colunas (mesmo que em ordens diferentes) n√£o gerem m√∫ltiplas chamadas ao modelo.

### Feedback e altera√ß√£o humana

Um endpoint dedicado foi projetado para permitir interven√ß√£o humana no processo de agrupamento, possibilitando a corre√ß√£o manual de decis√µes tomadas automaticamente pelo algoritmo. A principal motiva√ß√£o √© reconhecer que, apesar da efic√°cia das m√©tricas de similaridade e do uso pontual de modelos de linguagem, casos amb√≠guos ou espec√≠ficos do dom√≠nio podem exigir valida√ß√£o humana.

Por meio do endpoint, √© poss√≠vel mover manualmente um item de um grupo para outro, ou ainda for√ßar a cria√ß√£o de um novo grupo. Opcionalmente, o usu√°rio pode fornecer uma lista de palavras-chave relevantes, que passam a caracterizar o grupo de destino. Essas palavras-chave s√£o utilizadas como sinais adicionais em an√°lises futuras, ajudando a refor√ßar a identidade sem√¢ntica do grupo.

Ap√≥s a realoca√ß√£o do item, o sistema executa uma etapa de verifica√ß√£o para identificar itens potencialmente mal posicionados. Essa verifica√ß√£o analisa os itens do grupo de origem em rela√ß√£o ao grupo de destino, buscando casos em que outros itens possam ter sido afetados pela corre√ß√£o manual e tamb√©m devam ser reconsiderados. Os itens considerados suspeitos s√£o retornados na resposta do endpoint.

Dessa forma, o endpoint n√£o apenas permite a corre√ß√£o pontual de um erro, mas tamb√©m promove um ciclo de feedback humano no processo de agrupamento, auxiliando na identifica√ß√£o de inconsist√™ncias e contribuindo para a melhoria cont√≠nua da qualidade dos grupos ao longo do tempo.

## üîÑ Fluxo geral do algoritmo

1. Leitura do arquivo estruturado (CSV) e sele√ß√£o autom√°tica das colunas relevantes.
2. Cria√ß√£o de itens a partir das descri√ß√µes normalizadas.
3. C√°lculo de similaridade entre o novo item e itens j√° agrupados.
4. Atribui√ß√£o autom√°tica a um grupo existente (ou cria√ß√£o de um novo grupo) por meio de m√©tricas de similaridade e, quando necess√°rio, do uso de um modelo de linguagem.  
   - **Obs.**: um pressuposto importante √© que itens provenientes de um mesmo cat√°logo n√£o s√£o equivalentes entre si. Esse fato √© especialmente relevante durante a inicializa√ß√£o, quando cada item do primeiro cat√°logo origina um novo grupo.
5. Possibilidade de interven√ß√£o humana para corre√ß√£o manual e refinamento dos grupos.
6. Reavalia√ß√£o de itens potencialmente impactados ap√≥s interven√ß√µes manuais.

Sobre a implementa√ß√£o, o estado global da aplica√ß√£o √© mantido em mem√≥ria e protegido por locks ass√≠ncronos, garantindo consist√™ncia em cen√°rios de acesso concorrente √† API.

## üåê API

A aplica√ß√£o exp√µe uma API REST constru√≠da com para:
- ingest√£o de arquivos CSV;
- interven√ß√£o humana para corre√ß√£o de grupos;
- inspe√ß√£o do estado atual dos agrupamentos.

**Nota**: ap√≥s iniciar a aplica√ß√£o, a documenta√ß√£o interativa pode ser acessada em: `/docs`.

## üìÇ Estrutura do projeto

- **Arquivos na raiz**
  - `README.md`: documenta√ß√£o principal do projeto, contendo a descri√ß√£o do problema, abordagem adotada e instru√ß√µes de uso.
  - `desc.md`: descri√ß√£o detalhada do desafio proposto.
  - `pyproject.toml`, `.python-version` e `uv.lock`: arquivos de configura√ß√£o do ambiente e depend√™ncias.
  - `tests.ipynb`: notebook contendo experimentos e resultados a partir dos quais decis√µes t√©cnicas foram tomadas.
  - `dump/`: diret√≥rio utilizado para persistir o estado final dos agrupamentos para inspe√ß√£o ap√≥s encerrar a API.
  - `exemplos/`: arquivos CSV de exemplo, representando cat√°logos de diferentes fornecedores.

- **src/**
  - `main.py`: ponto de entrada da aplica√ß√£o e defini√ß√£o dos endpoints da API.
  - `state.py`: defini√ß√£o do estado global da aplica√ß√£o, respons√°vel por armazenar grupos, itens, caches e mecanismos de sincroniza√ß√£o.
  - `config/`: configura√ß√µes gerais da aplica√ß√£o, incluindo *settings*, *logging* e *prompts* utilizados pelo modelo de linguagem.
  - `domain/`: defini√ß√£o das entidades centrais do dom√≠nio.
  - `llm/`: abstra√ß√£o e integra√ß√£o com o modelo de linguagem utilizado para decis√µes sem√¢nticas.
  - `service/`: servi√ßos que encapsulam a l√≥gica de aplica√ß√£o, como cria√ß√£o de itens a partir de CSVs, agrupamento autom√°tico e identifica√ß√£o de itens suspeitos.

## üë®üèª‚Äçüíª Como usar

1. Clone o reposit√≥rio
```bash
git clone https://github.com/joaoloss/neofuturo-desafio-tecnico.git
cd neofuturo-desafio-tecnico
```

2. Crie um `.env`
```
OPENAI_API_KEY=<sua-chave-api>
LLM_MODEL_NAME=<gpt-5-nano-2025-08-07 ou outro modelo>
```

3. Inicialize o ambiente com [uv](https://docs.astral.sh/uv/)
```bash
uv sync
```

4. Execu√ß√£o do Programa
```bash
uv run fastapi run ./src/main.py
```

## üß© Melhorias e limita√ß√µes reconhecidas

Como o algoritmo √© apenas um prot√≥tipo, √© importante pontuar limita√ß√µes/melhorias reconhecidas:

1. Tratativa de erros.
2. Suporte para mais tipos de arquivo.
3. Armazenamento em mem√≥ria: para simplificar o desenvolvimento e acelerar testes, optou-se por n√£o utilizar um SGBD. Todo o estado da aplica√ß√£o √© mantido em mem√≥ria e, portanto, √© perdido ap√≥s o encerramento do programa. Uma evolu√ß√£o natural seria a persist√™ncia dos dados em um banco de dados.
4. Atualmente, a cria√ß√£o de palavras-chave associadas aos grupos ocorre apenas ap√≥s interven√ß√£o manual humana. √â poss√≠vel evoluir esse mecanismo para uma abordagem mais din√¢mica, em que as palavras-chave sejam automaticamente inferidas a partir dos termos mais frequentes ou mais representativos dos itens de cada grupo.
5. Estrat√©gias de encurtamento de descri√ß√µes (removendo palavras irrelevantes ou pouco significativas) podem se mostrar essencias pensando em escalabilidade.
6. Os pesos das m√©tricas de similaridade e os *thresholds* foram definidos empiricamente. Uma poss√≠vel melhoria seria automatizar esse processo por meio de valida√ß√£o com dados rotulados, otimiza√ß√£o de hiperpar√¢metros ou t√©cnicas adaptativas que ajustem esses valores ao longo do tempo.